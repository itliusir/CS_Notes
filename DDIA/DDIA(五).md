# 分区

这里要讨论的分区并不是网络分区，而是对大的数据集进行分片。

分区主要是为了 **可扩展性** ，不同的分区可以放在不共享集群中的不同节点上。

分区通常与复制结合使用，使得每个分区的副本存储在多个节点上。 这意味着，即使每条记录属于一个分区，它仍然可以存储在多个不同的节点上以获得容错能力。

<img src="http://qiniu.itliusir.com/ddia_partition.png" style="zoom:50%;" />



### 1.1 根据键的范围分区

在每个分区中，我们可以按照一定的顺序保存键（LSM-树）。好处是进行范围扫描非常简单，您可以将键作为联合索引来处理，以便在一次查询中获取多个相关记录

> 存在偏斜和热点的风险，一般按照建来分区的会动态创建分区，分区增长到超过配置的大小时，会被分为两个分区，每个分区约占一半的数据。与之相反，如果大量数据被删除并且分区缩小到某个阈值以下，则可以将其与相邻分区合并。此过程与B树顶层发生的过程类似

### 1.2 根据键的散列分区

采用 一致性hash 等技术，使数据均匀分散在不同分片，但是对于范围查询很不友好。

> 可以发现不管怎么样 实际热点的风险总是存在，例如微博的一个大V、热门商品、热门搜索等
>
> 一个简单的方法是在主键的开始或结尾添加一个随机数。只要一个两位数的十进制随机数就可以将主键分散为100种不同的主键,从而存储在不同的分区中。

### 1.3 根据关键词的二级索引

我们可以构建一个覆盖所有分区数据的**全局索引**，而不是给每个分区创建自己的次级索引（本地索引）。但是，我们不能只把这个索引存储在一个节点上，因为它可能会成为瓶颈，违背了分区的目的。全局索引也必须进行分区，但可以采用与主键不同的分区方式。

<img src="http://qiniu.itliusir.com/ddia_partition_index2.png" style="zoom:50%;" />

### 1.4 分区再平衡

随着时间的推移，各个分片数据会慢慢失衡(或者新加入了一些空节点)，而要达到再次平衡的话，都要满足如下的一些最低要求：

- 再平衡后能达到想要的负载平衡效果
- 再平衡发生时，分片应该继续接受读取和写入
- 节点之间只移动必须的数据，减少平衡时间



#### 1.4.1 按照固定数量设计再平衡

在最初设计时候，创建比节点更多的分区，例如每个节点负责100个分区，当有一个节点被加入集群中(不平衡)，会去每个节点窃取一些分区从而再次达到平衡。

> 这样还可以针对不同机器的配置调整不同的分区数量来达到处理能力的平衡

#### 1.4.2 动态分区

每个分区分配给一个节点，每个节点可以处理多个分区，就像固定数量的分区一样。大型分区拆分后，可以将其中的一半转移到另一个节点，以平衡负载。在HBase中，分区文件的传输通过HDFS（底层分布式文件系统）来实现。

